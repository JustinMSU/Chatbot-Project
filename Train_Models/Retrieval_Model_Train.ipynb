{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3082a278-3fe1-4d5b-8c3e-d4d23177469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.nn import init\n",
    "import torch.nn.utils.rnn \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import datetime\n",
    "from datasets import load_dataset\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52deebc4-d0a4-45fe-bb0e-1e0e4808741e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d5a216-b218-407f-86c2-8f3e4012e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialog pairs consist of [context, response, label]\n",
    "def get_dialog_pairs(dataset, evalset):\n",
    "    dataset_length = len(dataset)\n",
    "    dialog_pairs = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip() \n",
    "            if not inputLine or not isinstance(inputLine, str): \n",
    "                inputLine = 'Nothing'\n",
    "            if isinstance(dataset[i][j], str):\n",
    "                targetLine = dataset[i][j].strip()\n",
    "            else:\n",
    "                targetLine = dataset[i][j]['text'].strip() \n",
    "            if not targetLine or not isinstance(targetLine, str): \n",
    "                targetLine = 'Nothing'\n",
    "            if isinstance(inputLine, str) and isinstance(targetLine, str) and inputLine and targetLine:\n",
    "                if evalset[i] >= 2:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "                inputLine = normalizeString(inputLine)\n",
    "                targetLine = normalizeString(targetLine)\n",
    "                dialog_pairs.append([inputLine, targetLine, label])\n",
    "\n",
    "    return dialog_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a9fd00-e868-4da2-bb9e-78b64982b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of individual sentences\n",
    "def get_dialog(dataset):\n",
    "    dataset_length = len(dataset)\n",
    "    dialog = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        \n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip()\n",
    "                \n",
    "            if not isinstance(inputLine, str) or not inputLine or len(inputLine.split()) <= 0: \n",
    "                continue\n",
    "            inputLine = normalizeString(inputLine)\n",
    "            dialog.append([inputLine])\n",
    "\n",
    "    return dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfe3d66-7dd0-414d-8e07-80c5f0fec98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4cd1fe2-b3ce-4c5b-abcd-edd364eac2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    if isinstance(s, str): \n",
    "        s = unicodeToAscii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "        s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9ecb98-4d83-4cc6-90dd-c060297ae4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_list(list):\n",
    "    random.shuffle(list)\n",
    "\n",
    "def create_vocab(dialog):\n",
    "    vocab = []\n",
    "    word_freq = {}\n",
    "    \n",
    "    for sentence in dialog:\n",
    "        sen = \"\".join(c for c in sentence)\n",
    "        train_words = str(sen).split(\" \")\n",
    "        \n",
    "        for word in train_words:\n",
    "          \n",
    "            if word.lower() not in vocab:\n",
    "                vocab.append(word.lower())         \n",
    "                       \n",
    "            if word.lower() not in word_freq:\n",
    "                word_freq[word.lower()] = 1\n",
    "            else:\n",
    "                #type(word)\n",
    "                word_freq[word] += 1\n",
    "    \n",
    "    word_freq_sorted = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "    vocab = [\"<UNK>\"] + [pair[0] for pair in word_freq_sorted]\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def create_word_to_id(vocab):             \n",
    "    word_to_id = {word: id for id, word in enumerate(vocab)}\n",
    "    \n",
    "    return word_to_id\n",
    "\n",
    "\n",
    "def create_id_to_vec(word_to_id, glovefile): \n",
    "    lines = open(glovefile, 'r', encoding='utf-8').readlines()\n",
    "    id_to_vec = {}\n",
    "    vector = None\n",
    "    \n",
    "    for line in lines:\n",
    "        word = line.split()[0]\n",
    "        vector = np.array(line.split()[1:], dtype='float32') #32\n",
    "        \n",
    "        if word in word_to_id:\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(vector))\n",
    "            \n",
    "    for word, id in word_to_id.items(): \n",
    "        if word_to_id[word] not in id_to_vec:\n",
    "            v = np.zeros(*vector.shape, dtype='float32')\n",
    "            v[:] = np.random.randn(*v.shape)*0.01\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(v))\n",
    "            \n",
    "    embedding_dim = id_to_vec[0].shape[0]\n",
    "    \n",
    "    return id_to_vec, embedding_dim\n",
    "\n",
    "def load_id(sentence, word_to_id):\n",
    "    sentence_ids = []\n",
    "\n",
    "    max_sentence_len = 160\n",
    "    \n",
    "    sentence_words = sentence.split()\n",
    "    if len(sentence_words) > max_sentence_len:\n",
    "        sentence_words = sentence_words[:max_sentence_len]\n",
    "    for word in sentence_words:\n",
    "        if word in word_to_id:\n",
    "            sentence_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            sentence_ids.append(0) #UNK\n",
    "\n",
    "    return sentence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0398a8b1-6101-474f-8391-4e7c4e0ff633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.sentences = []\n",
    "        self.word2id = {}\n",
    "        self.id2vec = None\n",
    "        \n",
    "    def save(self):\n",
    "        torch.save({\n",
    "                'voc_dict': self.__dict__,\n",
    "            }, os.path.join('saveDir', 'save_voc.tar'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.__dict__ = checkpoint['voc_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "958a2994-ea8e-4934-8822-6dde577d4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(embedding_dim):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    raw_dataset = load_dataset(\"conv_ai_2\")\n",
    "    raw_dataset1 = load_dataset(\"daily_dialog\")\n",
    "    train_dataset = raw_dataset[\"train\"]\n",
    "    train_dataset1 = raw_dataset1[\"train\"]\n",
    "    raw_dialog_list = train_dataset[\"dialog\"]\n",
    "    raw_dialog_list1 = train_dataset1[\"dialog\"]\n",
    "    \n",
    "    eval_list = train_dataset[\"eval_score\"]\n",
    "    eval_list1 = [2 for i in range(len(raw_dialog_list1))]\n",
    "    \n",
    "    dialog_pairs = get_dialog_pairs(raw_dialog_list, eval_list)\n",
    "    dialog_pairs1 = get_dialog_pairs(raw_dialog_list1, eval_list1)\n",
    "    dialog_pairs.extend(dialog_pairs1)\n",
    "    #dialog_pairs = [[normalizeString(s) for s in l] for l in dialog_pairs]\n",
    "    only_dialog_pairs = []\n",
    "    for i in range(len(dialog_pairs)):\n",
    "        only_dialog_pairs.append(dialog_pairs[i][0:2])\n",
    "    \n",
    "    dialog_indiv = get_dialog(raw_dialog_list)\n",
    "    dialog_indiv1 = get_dialog(raw_dialog_list1)\n",
    "    dialog_indiv.extend(dialog_indiv1)\n",
    "    \n",
    "    #dialog_indiv = [[normalizeString(s) for s in l] for l in dialog_indiv]\n",
    "    trimmed_sentences = []\n",
    "    for s in dialog_indiv:\n",
    "        if isinstance(s[0], str) and len(s[0].split()) < 15:\n",
    "            trimmed_sentences.append(s)\n",
    "    \n",
    "    vocab = create_vocab(trimmed_sentences)\n",
    "    voc = Voc()\n",
    "    voc.vocab = vocab\n",
    "    voc.sentences = trimmed_sentences\n",
    "    shuffle_list(dialog_pairs)\n",
    "    \n",
    "    for pair in dialog_pairs:\n",
    "        if len(pair[0].split()) <= 0:\n",
    "            pair[0] = 'Oh'\n",
    "        if len(pair[1].split()) <= 0:\n",
    "            pair[1] = 'Oh'\n",
    "            \n",
    "    # Trim pairs to max 14 words and under\n",
    "    trimmed_pairs = []\n",
    "    for pair in dialog_pairs:\n",
    "        if isinstance(pair[0], str) and len(pair[0].split()) < 15 and isinstance(pair[1], str) and len(pair[1].split()) < 15:\n",
    "            trimmed_pairs.append(pair)\n",
    "    \n",
    "    #training_data = trimmed_pairs\n",
    "    training_data = trimmed_pairs[:-(int(len(trimmed_pairs) / 10))]\n",
    "    \n",
    "    word_to_id = create_word_to_id(vocab)\n",
    "    voc.word2id = word_to_id\n",
    "    id_to_vec, emb_dim = create_id_to_vec(word_to_id, 'saveDir/GloVe/glove.6B.%dd.txt' %embedding_dim)\n",
    "    voc.id2vec = id_to_vec\n",
    "    voc.save()\n",
    "\n",
    "    validation_data = trimmed_pairs[-(int(len(trimmed_pairs) / 10)):]\n",
    "    \n",
    "    return training_data, validation_data, voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a725df3-4744-4604-816a-d9fbabbdc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0  \n",
    "SOS_token = 1 \n",
    "EOS_token = 2\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "# Returns padded sequence tensor and lengths\n",
    "def sequenceVar(l, word_to_id):\n",
    "    indexes_batch = [load_id(sentence, word_to_id) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(pair_batch, word_to_id):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch, labels = [], [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        labels.append(pair[2])\n",
    "    inp, lengths = sequenceVar(input_batch, word_to_id)\n",
    "    output, lengths1 = sequenceVar(output_batch, word_to_id)\n",
    "    return inp, lengths, output, lengths1, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca2262d-7eb1-4d9c-8542-1f86d5c05696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "            hidden_size,\n",
    "            vocab_size,\n",
    "            id_to_vec,\n",
    "            embedding,\n",
    "            p_dropout): \n",
    "    \n",
    "            super(Encoder, self).__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.vocab_size = vocab_size\n",
    "            self.id_to_vec = id_to_vec\n",
    "            self.p_dropout = p_dropout\n",
    "            self.embedding = embedding\n",
    "            self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "            self.dropout_layer = nn.Dropout(self.p_dropout) \n",
    "\n",
    "            self.init_weights()\n",
    "            \n",
    "    def init_weights(self):\n",
    "        init.uniform(self.lstm.weight_ih_l0, a = -0.01, b = 0.01)\n",
    "        init.orthogonal(self.lstm.weight_hh_l0)\n",
    "        self.lstm.weight_ih_l0.requires_grad = True\n",
    "        self.lstm.weight_hh_l0.requires_grad = True\n",
    "        \n",
    "        embedding_weights = torch.FloatTensor(self.vocab_size, self.hidden_size)\n",
    "        embedding_weights = embedding_weights.to(device)\n",
    "        for id, vec in self.id_to_vec.items():\n",
    "            embedding_weights[id] = vec\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad = True)\n",
    "            \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embeddings = self.embedding(input_seq)\n",
    "        embeddings = embeddings.to(device)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeddings, input_lengths, enforce_sorted = False)\n",
    "        \n",
    "        _, (last_hidden, _) = self.lstm(packed, hidden)\n",
    "        last_hidden = self.dropout_layer(last_hidden[-1])\n",
    "        return last_hidden\n",
    "    \n",
    "class DualEncoder(nn.Module):\n",
    "     \n",
    "    def __init__(self, encoder):\n",
    "        super(DualEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_size = self.encoder.hidden_size\n",
    "        M = torch.FloatTensor(self.hidden_size, self.hidden_size)\n",
    "        M = M.to(device)\n",
    "        init.xavier_normal(M)\n",
    "        self.M = nn.Parameter(M, requires_grad = True)\n",
    "\n",
    "    def forward(self, input_seq, response_seq, input_lengths, response_lengths):\n",
    "        context_last_hidden = self.encoder(input_seq, input_lengths)\n",
    "        context_last_hidden = context_last_hidden.to(device)\n",
    "        response_last_hidden = self.encoder(response_seq, response_lengths)\n",
    "        response_last_hidden = response_last_hidden.to(device)\n",
    "        \n",
    "        context = context_last_hidden.mm(self.M)\n",
    "        context = context.view(-1, 1, self.hidden_size)\n",
    "        context = context.to(device)\n",
    "        \n",
    "        response = response_last_hidden.view(-1, self.hidden_size, 1) \n",
    "        response = response.to(device)\n",
    "        \n",
    "        score = torch.bmm(context, response).view(-1, 1)\n",
    "        score = score.to(device)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fb4b16-24a0-4a52-bf93-e3069e281576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_model(hidden_size, vocab_size, id_to_vec, embedding, p_dropout):\n",
    "\n",
    "    encoder = Encoder(\n",
    "            hidden_size = hidden_size,\n",
    "            vocab_size = vocab_size,\n",
    "            id_to_vec = id_to_vec,\n",
    "            embedding = embedding,\n",
    "            p_dropout = p_dropout)\n",
    "\n",
    "    dual_encoder = DualEncoder(encoder)\n",
    "    \n",
    "    return encoder, dual_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea384b9e-b547-40f1-aea1-46cc74dbf6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_count(score, label):\n",
    "    corr = False\n",
    "    if ((score >= 0.5) and (label >= 1)) or ((score < 0.5) and (label  <= 0)):\n",
    "        corr = True\n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_accuracy(correct_count, length):\n",
    "    accuracy = correct_count/length\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f6fd99-b86c-4588-90c8-c8453b4f4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func, is_train = True):\n",
    "\n",
    "    if is_train:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    context = context.to(device)\n",
    "    response = response.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "    lengths1 = lengths1.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    sum_loss = 0.0\n",
    "    correct_count = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    score = c_encoder(context, response, lengths, lengths1)\n",
    "    total_count = 0\n",
    "    for n in range(len(score)):\n",
    "        total_count += 1\n",
    "        label = autograd.Variable(torch.DoubleTensor(torch.from_numpy(np.array(labels[n]).astype(float).reshape(1,1))), requires_grad = False)\n",
    "        label = label.to(device)\n",
    "        loss = loss_func(score[n].reshape(1,1), label)\n",
    "        sum_loss += loss.item()\n",
    "        if increase_count(score[n].item(), label.item()):\n",
    "            correct_count += 1\n",
    "\n",
    "    if is_train:\n",
    "        # Perform backpropatation\n",
    "        loss.backward()\n",
    "        # Adjust model weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss, correct_count, total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec9088f-a802-4525-9401-0caf0a9a3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIterAll(training_data, validation_data, voc, c_encoder, learning_rate, l2_penalty, n_iteration, batch_size, epochs):\n",
    "\n",
    "    optimizer = torch.optim.Adam(c_encoder.parameters(), lr = learning_rate, weight_decay = l2_penalty)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    loss_func = loss_func.to(device)\n",
    "    total_training_accuracy = 0\n",
    "    best_validation_accuracy = 0\n",
    "    best_training_accuracy = 0\n",
    "    \n",
    "    word_to_id = voc.word2id\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        training_batches = [batch2TrainData([random.choice(training_data) for _ in range(batch_size)], word_to_id)\n",
    "                          for _ in range(n_iteration)]\n",
    "\n",
    "        validation_batches = [batch2TrainData([random.choice(validation_data) for _ in range(batch_size)], word_to_id)\n",
    "                          for _ in range(n_iteration)]\n",
    "\n",
    "        # Initializations\n",
    "        start_iteration = 1\n",
    "        print_loss = 0\n",
    "\n",
    "        sum_loss_training = 0.0\n",
    "        training_correct_count = 0\n",
    "        training_total_count = 0\n",
    "        #c_encoder.train()\n",
    "\n",
    "        # Training loop\n",
    "        c_encoder.train()\n",
    "        i = 0\n",
    "        for iteration in range(start_iteration, n_iteration + 1):\n",
    "            if (i % 1000 == 0):\n",
    "                print('Iteration ', i)\n",
    "            i += 1\n",
    "            training_batch = training_batches[iteration - 1]\n",
    "            # Extract fields from batch\n",
    "            context, lengths, response, lengths1, labels = training_batch\n",
    "\n",
    "            # Run a training iteration with batch\n",
    "            loss, correct_count, total_count = train(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func)\n",
    "            training_correct_count += correct_count\n",
    "            training_total_count += total_count\n",
    "            sum_loss_training += loss\n",
    "            print_loss += loss\n",
    "\n",
    "            # Print progress\n",
    "            if iteration % 1000 == 0:\n",
    "                print_loss_avg = print_loss / 1000\n",
    "                print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "                print('Correct count: ', training_correct_count)\n",
    "                print('Total count: ', training_total_count)\n",
    "                print_loss = 0\n",
    "\n",
    "        training_accuracy = get_accuracy(training_correct_count, training_total_count)\n",
    "        \n",
    "        c_encoder.eval()\n",
    "        \n",
    "        # Iterate through validation set\n",
    "        validation_correct_count = 0\n",
    "        validation_total_count = 0\n",
    "        sum_loss_validation = 0.0\n",
    "        i = 0\n",
    "        for iteration in range(start_iteration, n_iteration + 1):\n",
    "            if (i % 1000 == 0):\n",
    "                print('Iteration val ', i)\n",
    "            i += 1\n",
    "            validation_batch = validation_batches[iteration - 1]\n",
    "            # Extract fields from batch\n",
    "            context, lengths, response, lengths1, labels = validation_batch\n",
    "\n",
    "            # Run a training iteration with batch\n",
    "            loss, correct_count, total_count = train(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func, False)\n",
    "            sum_loss_validation += loss\n",
    "            validation_correct_count += correct_count\n",
    "            validation_total_count += total_count\n",
    "\n",
    "        validation_accuracy = get_accuracy(validation_correct_count, validation_total_count)\n",
    "\n",
    "        print(str(datetime.datetime.now()).split('.')[0], \n",
    "              \"Epoch: %d/%d\" %(epoch,epochs),  \n",
    "              \"Train Accuracy: %.3f\" %(training_accuracy), \n",
    "              \"Validation Accuracy: %.3f\" %(validation_accuracy))\n",
    "\n",
    "        # Saving best result\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "            print(\"Saving new best\")\n",
    "            torch.save({\n",
    "                    'en': c_encoder.state_dict(),\n",
    "                    'opt': optimizer.state_dict(),\n",
    "                    'voc_dict': voc.__dict__\n",
    "                }, os.path.join('saveDir', 'retrieval_model_Val4.tar'))\n",
    "                \n",
    "        # Saving best train result\n",
    "        if training_accuracy > best_training_accuracy:\n",
    "            best_training_accuracy = training_accuracy\n",
    "            torch.save({\n",
    "                        'en': c_encoder.state_dict(),\n",
    "                        'opt': optimizer.state_dict(),\n",
    "                        'voc_dict': voc.__dict__\n",
    "                }, os.path.join('saveDir', 'retrieval_model_Train4.tar'))\n",
    "        \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Training and validation epochs finished.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6880bf9a-d2b6-470e-ac12-8925a0196e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conv_ai_2 (C:\\Users\\justi\\.cache\\huggingface\\datasets\\conv_ai_2\\conv_ai_2\\1.0.0\\11d600ddce66bb9d07ca50d1b55b488145ef0d5d0206168c32f1043677875865)\n",
      "Using custom data configuration default\n",
      "Reusing dataset daily_dialog (C:\\Users\\justi\\.cache\\huggingface\\datasets\\daily_dialog\\default\\1.0.0\\c03444008e9508b8b76f1f6793742d37d5e5f83364f8d573c2747bff435ea55c)\n"
     ]
    }
   ],
   "source": [
    "n_iteration = 8000\n",
    "batch_size = 64\n",
    "training_data, validation_data, voc = prepareData(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6509b2b9-10f6-424e-af99-5f00ac87a1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "vocab_size = len(voc.vocab)\n",
    "id_to_vec = voc.id2vec\n",
    "embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "encoder, dual_encoder = creating_model(hidden_size, vocab_size, id_to_vec, embedding, p_dropout = 0.85)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "dual_encoder = dual_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "372e3de3-8852-4179-a5c9-71117cd39df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Iteration: 1000; Percent complete: 12.5%; Average loss: 0.5666\n",
      "Correct count:  2441\n",
      "Total count:  4000\n",
      "Iteration  1000\n",
      "Iteration: 2000; Percent complete: 25.0%; Average loss: 0.4819\n",
      "Correct count:  5572\n",
      "Total count:  8000\n",
      "Iteration  2000\n",
      "Iteration: 3000; Percent complete: 37.5%; Average loss: 0.4894\n",
      "Correct count:  8730\n",
      "Total count:  12000\n",
      "Iteration  3000\n",
      "Iteration: 4000; Percent complete: 50.0%; Average loss: 0.5043\n",
      "Correct count:  11907\n",
      "Total count:  16000\n",
      "Iteration  4000\n",
      "Iteration: 5000; Percent complete: 62.5%; Average loss: 0.4588\n",
      "Correct count:  15176\n",
      "Total count:  20000\n",
      "Iteration  5000\n",
      "Iteration: 6000; Percent complete: 75.0%; Average loss: 0.4486\n",
      "Correct count:  18485\n",
      "Total count:  24000\n",
      "Iteration  6000\n",
      "Iteration: 7000; Percent complete: 87.5%; Average loss: 0.4496\n",
      "Correct count:  21810\n",
      "Total count:  28000\n",
      "Iteration  7000\n",
      "Iteration: 8000; Percent complete: 100.0%; Average loss: 0.4486\n",
      "Correct count:  25160\n",
      "Total count:  32000\n",
      "Iteration val  0\n",
      "Iteration val  1000\n",
      "Iteration val  2000\n",
      "Iteration val  3000\n",
      "Iteration val  4000\n",
      "Iteration val  5000\n",
      "Iteration val  6000\n",
      "Iteration val  7000\n",
      "2021-12-15 17:42:33 Epoch: 0/5 Train Accuracy: 0.786 Validation Accuracy: 0.874\n",
      "Saving new best\n",
      "Iteration  0\n",
      "Iteration: 1000; Percent complete: 12.5%; Average loss: 0.4179\n",
      "Correct count:  3375\n",
      "Total count:  4000\n",
      "Iteration  1000\n",
      "Iteration: 2000; Percent complete: 25.0%; Average loss: 0.4665\n",
      "Correct count:  6674\n",
      "Total count:  8000\n",
      "Iteration  2000\n",
      "Iteration: 3000; Percent complete: 37.5%; Average loss: 0.4408\n",
      "Correct count:  10052\n",
      "Total count:  12000\n",
      "Iteration  3000\n",
      "Iteration: 4000; Percent complete: 50.0%; Average loss: 0.4248\n",
      "Correct count:  13419\n",
      "Total count:  16000\n",
      "Iteration  4000\n",
      "Iteration: 5000; Percent complete: 62.5%; Average loss: 0.3990\n",
      "Correct count:  16874\n",
      "Total count:  20000\n",
      "Iteration  5000\n",
      "Iteration: 6000; Percent complete: 75.0%; Average loss: 0.4132\n",
      "Correct count:  20269\n",
      "Total count:  24000\n",
      "Iteration  6000\n",
      "Iteration: 7000; Percent complete: 87.5%; Average loss: 0.4118\n",
      "Correct count:  23717\n",
      "Total count:  28000\n",
      "Iteration  7000\n",
      "Iteration: 8000; Percent complete: 100.0%; Average loss: 0.4320\n",
      "Correct count:  27037\n",
      "Total count:  32000\n",
      "Iteration val  0\n",
      "Iteration val  1000\n",
      "Iteration val  2000\n",
      "Iteration val  3000\n",
      "Iteration val  4000\n",
      "Iteration val  5000\n",
      "Iteration val  6000\n",
      "Iteration val  7000\n",
      "2021-12-15 17:44:34 Epoch: 1/5 Train Accuracy: 0.845 Validation Accuracy: 0.811\n",
      "Iteration  0\n",
      "Iteration: 1000; Percent complete: 12.5%; Average loss: 0.4271\n",
      "Correct count:  3323\n",
      "Total count:  4000\n",
      "Iteration  1000\n",
      "Iteration: 2000; Percent complete: 25.0%; Average loss: 0.4356\n",
      "Correct count:  6666\n",
      "Total count:  8000\n",
      "Iteration  2000\n",
      "Iteration: 3000; Percent complete: 37.5%; Average loss: 0.4161\n",
      "Correct count:  10107\n",
      "Total count:  12000\n",
      "Iteration  3000\n",
      "Iteration: 4000; Percent complete: 50.0%; Average loss: 0.3984\n",
      "Correct count:  13543\n",
      "Total count:  16000\n",
      "Iteration  4000\n",
      "Iteration: 5000; Percent complete: 62.5%; Average loss: 0.4329\n",
      "Correct count:  16955\n",
      "Total count:  20000\n",
      "Iteration  5000\n",
      "Iteration: 6000; Percent complete: 75.0%; Average loss: 0.3692\n",
      "Correct count:  20391\n",
      "Total count:  24000\n",
      "Iteration  6000\n",
      "Iteration: 7000; Percent complete: 87.5%; Average loss: 0.4119\n",
      "Correct count:  23822\n",
      "Total count:  28000\n",
      "Iteration  7000\n",
      "Iteration: 8000; Percent complete: 100.0%; Average loss: 0.4031\n",
      "Correct count:  27259\n",
      "Total count:  32000\n",
      "Iteration val  0\n",
      "Iteration val  1000\n",
      "Iteration val  2000\n",
      "Iteration val  3000\n",
      "Iteration val  4000\n",
      "Iteration val  5000\n",
      "Iteration val  6000\n",
      "Iteration val  7000\n",
      "2021-12-15 17:46:35 Epoch: 2/5 Train Accuracy: 0.852 Validation Accuracy: 0.881\n",
      "Saving new best\n",
      "Iteration  0\n",
      "Iteration: 1000; Percent complete: 12.5%; Average loss: 0.3829\n",
      "Correct count:  3483\n",
      "Total count:  4000\n",
      "Iteration  1000\n",
      "Iteration: 2000; Percent complete: 25.0%; Average loss: 0.4342\n",
      "Correct count:  6906\n",
      "Total count:  8000\n",
      "Iteration  2000\n",
      "Iteration: 3000; Percent complete: 37.5%; Average loss: 0.4081\n",
      "Correct count:  10316\n",
      "Total count:  12000\n",
      "Iteration  3000\n",
      "Iteration: 4000; Percent complete: 50.0%; Average loss: 0.3960\n",
      "Correct count:  13782\n",
      "Total count:  16000\n",
      "Iteration  4000\n",
      "Iteration: 5000; Percent complete: 62.5%; Average loss: 0.3714\n",
      "Correct count:  17278\n",
      "Total count:  20000\n",
      "Iteration  5000\n",
      "Iteration: 6000; Percent complete: 75.0%; Average loss: 0.3827\n",
      "Correct count:  20764\n",
      "Total count:  24000\n",
      "Iteration  6000\n",
      "Iteration: 7000; Percent complete: 87.5%; Average loss: 0.3976\n",
      "Correct count:  24235\n",
      "Total count:  28000\n",
      "Iteration  7000\n",
      "Iteration: 8000; Percent complete: 100.0%; Average loss: 0.4229\n",
      "Correct count:  27693\n",
      "Total count:  32000\n",
      "Iteration val  0\n",
      "Iteration val  1000\n",
      "Iteration val  2000\n",
      "Iteration val  3000\n",
      "Iteration val  4000\n",
      "Iteration val  5000\n",
      "Iteration val  6000\n",
      "Iteration val  7000\n",
      "2021-12-15 17:48:37 Epoch: 3/5 Train Accuracy: 0.865 Validation Accuracy: 0.890\n",
      "Saving new best\n",
      "Iteration  0\n",
      "Iteration: 1000; Percent complete: 12.5%; Average loss: 0.3889\n",
      "Correct count:  3463\n",
      "Total count:  4000\n",
      "Iteration  1000\n",
      "Iteration: 2000; Percent complete: 25.0%; Average loss: 0.3886\n",
      "Correct count:  6985\n",
      "Total count:  8000\n",
      "Iteration  2000\n",
      "Iteration: 3000; Percent complete: 37.5%; Average loss: 0.3822\n",
      "Correct count:  10492\n",
      "Total count:  12000\n",
      "Iteration  3000\n",
      "Iteration: 4000; Percent complete: 50.0%; Average loss: 0.4047\n",
      "Correct count:  13992\n",
      "Total count:  16000\n",
      "Iteration  4000\n",
      "Iteration: 5000; Percent complete: 62.5%; Average loss: 0.3829\n",
      "Correct count:  17496\n",
      "Total count:  20000\n",
      "Iteration  5000\n",
      "Iteration: 6000; Percent complete: 75.0%; Average loss: 0.3713\n",
      "Correct count:  21014\n",
      "Total count:  24000\n",
      "Iteration  6000\n",
      "Iteration: 7000; Percent complete: 87.5%; Average loss: 0.3446\n",
      "Correct count:  24570\n",
      "Total count:  28000\n",
      "Iteration  7000\n",
      "Iteration: 8000; Percent complete: 100.0%; Average loss: 0.3991\n",
      "Correct count:  28048\n",
      "Total count:  32000\n",
      "Iteration val  0\n",
      "Iteration val  1000\n",
      "Iteration val  2000\n",
      "Iteration val  3000\n",
      "Iteration val  4000\n",
      "Iteration val  5000\n",
      "Iteration val  6000\n",
      "Iteration val  7000\n",
      "2021-12-15 17:50:38 Epoch: 4/5 Train Accuracy: 0.876 Validation Accuracy: 0.897\n",
      "Saving new best\n",
      "2021-12-15 17:50:39 Training and validation epochs finished.\n"
     ]
    }
   ],
   "source": [
    "trainIterAll(training_data = training_data, validation_data = validation_data, voc = voc, c_encoder = dual_encoder, learning_rate = 0.0001, l2_penalty = 0.000001, n_iteration = n_iteration, batch_size = batch_size, epochs = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
