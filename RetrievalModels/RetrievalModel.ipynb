{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b3eb47-1150-4723-bf3f-a72548d779e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.nn import init\n",
    "import torch.nn.utils.rnn \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import datetime\n",
    "import operator\n",
    "import codecs\n",
    "from datasets import load_dataset\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5310c192-462b-4845-862e-adaaa2881dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d324499-defd-4fec-be9c-da69c827efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialog pairs consist of [context, response, label]\n",
    "def get_dialog_pairs(dataset, evalset):\n",
    "    dataset_length = len(dataset)\n",
    "    dialog_pairs = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip() \n",
    "            if not inputLine or not isinstance(inputLine, str): \n",
    "                inputLine = 'Nothing'\n",
    "            if isinstance(dataset[i][j], str):\n",
    "                targetLine = dataset[i][j].strip()\n",
    "            else:\n",
    "                targetLine = dataset[i][j]['text'].strip() \n",
    "            if not targetLine or not isinstance(targetLine, str): \n",
    "                targetLine = 'Nothing'\n",
    "            if isinstance(inputLine, str) and isinstance(targetLine, str) and inputLine and targetLine:\n",
    "                if evalset[i] >= 2:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "                dialog_pairs.append([inputLine, targetLine, label])\n",
    "\n",
    "    return dialog_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39186bdd-4704-4bb3-8cb6-6b69e07ce4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialog responses consist of [response]\n",
    "def get_dialog_responses(dataset):\n",
    "    dataset_length = len(dataset)\n",
    "    responses = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip() \n",
    "            if not inputLine or not isinstance(inputLine, str): \n",
    "                inputLine = 'Nothing'\n",
    "            if isinstance(dataset[i][j], str):\n",
    "                targetLine = dataset[i][j].strip()\n",
    "            else:\n",
    "                targetLine = dataset[i][j]['text'].strip() \n",
    "            if not targetLine or not isinstance(targetLine, str): \n",
    "                targetLine = 'Nothing'\n",
    "            if isinstance(inputLine, str) and isinstance(targetLine, str) and inputLine and targetLine:\n",
    "                responses.append([targetLine])\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc241c8-022e-47d7-9c45-82bc8f99f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of individual sentences\n",
    "def get_dialog(dataset):\n",
    "    dataset_length = len(dataset)\n",
    "    dialog = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip() \n",
    "            if not isinstance(inputLine, str) or not inputLine: \n",
    "                inputLine = 'Nothing'\n",
    "            dialog.append([inputLine])\n",
    "\n",
    "    return dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14db221c-4c92-4a04-bc0f-85fda88024b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd5d1105-3aaf-414c-95e6-98b8eb6d8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    if isinstance(s, str): \n",
    "        s = unicodeToAscii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "        s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a15fa3e7-89ff-4241-9e38-610a654583a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_list(list):\n",
    "    random.shuffle(list)\n",
    "\n",
    "def create_vocab(dialog):\n",
    "    vocab = []\n",
    "    word_freq = {}\n",
    "    \n",
    "    for sentence in dialog:\n",
    "        \n",
    "        train_words = str(sentence).split(\" \")\n",
    "        \n",
    "        for word in train_words:\n",
    "          \n",
    "            if word.lower() not in vocab:\n",
    "                vocab.append(word.lower())         \n",
    "                       \n",
    "            if word.lower() not in word_freq:\n",
    "                word_freq[word.lower()] = 1\n",
    "            else:\n",
    "                #type(word)\n",
    "                word_freq[word] += 1\n",
    "    \n",
    "    word_freq_sorted = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "    vocab = [\"<UNK>\"] + [pair[0] for pair in word_freq_sorted]\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def create_word_to_id(vocab):             \n",
    "    word_to_id = {word: id for id, word in enumerate(vocab)}\n",
    "    \n",
    "    return word_to_id\n",
    "\n",
    "\n",
    "def create_id_to_vec(word_to_id, glovefile): \n",
    "    lines = open(glovefile, 'r', encoding='utf-8').readlines()\n",
    "    id_to_vec = {}\n",
    "    vector = None\n",
    "    \n",
    "    for line in lines:\n",
    "        word = line.split()[0]\n",
    "        vector = np.array(line.split()[1:], dtype='float32') #32\n",
    "        \n",
    "        if word in word_to_id:\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(vector))\n",
    "            \n",
    "    for word, id in word_to_id.items(): \n",
    "        if word_to_id[word] not in id_to_vec:\n",
    "            v = np.zeros(*vector.shape, dtype='float32')\n",
    "            v[:] = np.random.randn(*v.shape)*0.01\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(v))\n",
    "            \n",
    "    embedding_dim = id_to_vec[0].shape[0]\n",
    "    \n",
    "    return id_to_vec, embedding_dim\n",
    "\n",
    "def load_id(sentence, word_to_id):\n",
    "    sentence_ids = []\n",
    "\n",
    "    max_sentence_len = 160\n",
    "    \n",
    "    sentence_words = sentence.split()\n",
    "    if len(sentence_words) > max_sentence_len:\n",
    "        sentence_words = sentence_words[:max_sentence_len]\n",
    "    for word in sentence_words:\n",
    "        if word in word_to_id:\n",
    "            sentence_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            sentence_ids.append(0) #UNK\n",
    "\n",
    "    return sentence_ids\n",
    "\n",
    "def load_ids(pair, word_to_id):\n",
    "    context_ids = []\n",
    "    response_ids = []\n",
    "\n",
    "    context_cell = pair[0]\n",
    "    response_cell = pair[1]\n",
    "\n",
    "    max_context_len = 160\n",
    "    \n",
    "    context_words = context_cell.split()\n",
    "    if len(context_words) > max_context_len:\n",
    "        context_words = context_words[:max_context_len]\n",
    "    for word in context_words:\n",
    "        if word in word_to_id:\n",
    "            context_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            context_ids.append(0) #UNK\n",
    "    \n",
    "    response_words = response_cell.split()\n",
    "    for word in response_words:\n",
    "        if word in word_to_id:\n",
    "            response_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            response_ids.append(0)\n",
    "\n",
    "    return context_ids, response_ids\n",
    "\n",
    "def load_ids_and_labels(pair, word_to_id):\n",
    "    context_ids = []\n",
    "    response_ids = []\n",
    "\n",
    "    context_cell = pair[0]\n",
    "    response_cell = pair[1]\n",
    "    label_cell = pair[2]\n",
    "\n",
    "    max_context_len = 160\n",
    "    \n",
    "    context_words = context_cell.split()\n",
    "    if len(context_words) > max_context_len:\n",
    "        context_words = context_words[:max_context_len]\n",
    "    for word in context_words:\n",
    "        if word in word_to_id:\n",
    "            context_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            context_ids.append(0) #UNK\n",
    "    \n",
    "    response_words = response_cell.split()\n",
    "    for word in response_words:\n",
    "        if word in word_to_id:\n",
    "            response_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            response_ids.append(0)\n",
    "    \n",
    "    label = np.array(label_cell).astype(np.float32)\n",
    "\n",
    "    return context_ids, response_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faee7bf3-e624-43fb-82e2-fccd96b41517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(embedding_dim):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    raw_dataset = load_dataset(\"conv_ai_2\")\n",
    "    raw_dataset1 = load_dataset(\"daily_dialog\")\n",
    "    train_dataset = raw_dataset[\"train\"]\n",
    "    train_dataset1 = raw_dataset1[\"train\"]\n",
    "    raw_dialog_list = train_dataset[\"dialog\"]\n",
    "    raw_dialog_list1 = train_dataset1[\"dialog\"]\n",
    "    \n",
    "    eval_list = train_dataset[\"eval_score\"]\n",
    "    eval_list1 = [2 for i in range(len(raw_dialog_list1))]\n",
    "    \n",
    "    dialog_pairs = get_dialog_pairs(raw_dialog_list, eval_list)\n",
    "    dialog_pairs1 = get_dialog_pairs(raw_dialog_list1, eval_list1)\n",
    "    dialog_pairs.extend(dialog_pairs1)\n",
    "    dialog_pairs = [[normalizeString(s) for s in l] for l in dialog_pairs]\n",
    "    only_dialog_pairs = []\n",
    "    for i in range(len(dialog_pairs)):\n",
    "        only_dialog_pairs.append(dialog_pairs[i][0:2])\n",
    "    \n",
    "    dialog_indiv = get_dialog(raw_dialog_list)\n",
    "    dialog_indiv1 = get_dialog(raw_dialog_list1)\n",
    "    dialog_indiv.extend(dialog_indiv1)\n",
    "    \n",
    "    dialog_indiv = [[normalizeString(s) for s in l] for l in dialog_indiv]\n",
    "    vocab = create_vocab(dialog_indiv)\n",
    "            \n",
    "    shuffle_list(dialog_pairs)\n",
    "    \n",
    "    for pair in dialog_pairs:\n",
    "        if len(pair[0].split()) <= 0:\n",
    "            pair[0] = 'Oh'\n",
    "        if len(pair[1].split()) <= 0:\n",
    "            pair[1] = 'Oh'\n",
    "    \n",
    "    training_data = dialog_pairs[:-(int(len(dialog_pairs) / 10))]\n",
    "    \n",
    "    word_to_id = create_word_to_id(vocab)\n",
    "    id_to_vec, emb_dim = create_id_to_vec(word_to_id, 'dataset/GloVe/glove.6B.%dd.txt' %embedding_dim)\n",
    "\n",
    "    validation_data = dialog_pairs[-(int(len(dialog_pairs) / 10)):]\n",
    "    print('Training data: ')\n",
    "    \n",
    "    return training_data, validation_data\n",
    "    #voc, pairs = readVocs(dialog_pairs, name)\n",
    "    #print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    #pairs = filterPairs(pairs)\n",
    "    #print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    #print(\"Counting words...\")\n",
    "    #for pair in pairs:\n",
    "       # voc.addSentence(pair[0])\n",
    "       # voc.addSentence(pair[1])\n",
    "    #print(\"Counted words:\", voc.num_words)\n",
    "    #return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6d12fe1-8c62-4288-b03a-76e995e2803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_responses():\n",
    "    raw_dataset = load_dataset(\"conv_ai_2\")\n",
    "    raw_dataset1 = load_dataset(\"daily_dialog\")\n",
    "    dataset = raw_dataset[\"train\"]\n",
    "    dataset1 = raw_dataset1[\"train\"]\n",
    "    dialog_list = dataset[\"dialog\"]\n",
    "    dialog_list1 = dataset1[\"dialog\"]\n",
    "    \n",
    "    dialog_indiv = get_dialog(dialog_list)\n",
    "    dialog_indiv1 = get_dialog(dialog_list1)\n",
    "    dialog_indiv.extend(dialog_indiv1)\n",
    "    \n",
    "    dialog_indiv = [[normalizeString(s) for s in l] for l in dialog_indiv]\n",
    "    vocab = create_vocab(dialog_indiv)\n",
    "    \n",
    "    responses = get_dialog_responses(dialog_list)\n",
    "    responses1 = get_dialog_responses(dialog_list1)\n",
    "    responses.append(responses1)\n",
    "    \n",
    "    word_to_id = create_word_to_id(vocab)\n",
    "    id_to_vec, emb_dim = create_id_to_vec(word_to_id, 'dataset/GloVe/glove.6B.50d.txt')\n",
    "    \n",
    "    return responses, vocab, word_to_id, id_to_vec, emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3099898-2ecb-439d-9d81-b4031b9c8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0  \n",
    "SOS_token = 1 \n",
    "EOS_token = 2\n",
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def contextVar(l):\n",
    "    indexes_batch = [load_id(sentence, word_to_id) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def responseVar(l):\n",
    "    indexes_batch = [load_id(sentence, word_to_id) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch, labels = [], [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "        labels.append(pair[2])\n",
    "    inp, lengths = contextVar(input_batch)\n",
    "    output, lengths1 = contextVar(output_batch)\n",
    "    return inp, lengths, output, lengths1, labels\n",
    "    #output, mask, max_target_len = responseVar(output_batch)\n",
    "    #return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "#small_batch_size = 5\n",
    "#batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "#input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "#print(\"input_variable:\", input_variable)\n",
    "#print(\"lengths:\", lengths)\n",
    "#print(\"target_variable:\", target_variable)\n",
    "#print(\"mask:\", mask)\n",
    "#print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c02b10d-fc2e-4a9e-9691-81d261fb2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "            emb_size, \n",
    "            hidden_size, \n",
    "            vocab_size, \n",
    "            p_dropout): \n",
    "    \n",
    "            super(Encoder, self).__init__()\n",
    "             \n",
    "            self.emb_size = emb_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.vocab_size = vocab_size\n",
    "            self.p_dropout = p_dropout\n",
    "       \n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
    "            self.lstm = nn.LSTM(self.emb_size, self.hidden_size)\n",
    "            self.dropout_layer = nn.Dropout(self.p_dropout) \n",
    "\n",
    "            self.init_weights()\n",
    "             \n",
    "    def init_weights(self):\n",
    "        init.uniform(self.lstm.weight_ih_l0, a = -0.01, b = 0.01)\n",
    "        init.orthogonal(self.lstm.weight_hh_l0)\n",
    "        self.lstm.weight_ih_l0.requires_grad = True\n",
    "        self.lstm.weight_hh_l0.requires_grad = True\n",
    "        \n",
    "        embedding_weights = torch.FloatTensor(self.vocab_size, self.emb_size)\n",
    "        embedding_weights = embedding_weights.to(device)\n",
    "            \n",
    "        for id, vec in id_to_vec.items():\n",
    "            embedding_weights[id] = vec\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad = True)\n",
    "            \n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embeddings = self.embedding(input_seq)\n",
    "        embeddings = embeddings.to(device)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeddings, input_lengths, enforce_sorted = False)\n",
    "        \n",
    "        _, (last_hidden, _) = self.lstm(packed, hidden)\n",
    "        last_hidden = self.dropout_layer(last_hidden[-1])\n",
    "        return last_hidden\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = embeddings.to(device)\n",
    "        _, (last_hidden, _) = self.lstm(embeddings)\n",
    "        last_hidden = self.dropout_layer(last_hidden[-1])\n",
    "\n",
    "        return last_hidden\n",
    "\n",
    "    \n",
    "class DualEncoder(nn.Module):\n",
    "     \n",
    "    def __init__(self, encoder):\n",
    "        super(DualEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_size = self.encoder.hidden_size\n",
    "        M = torch.FloatTensor(self.hidden_size, self.hidden_size)\n",
    "        M = M.to(device)\n",
    "        init.xavier_normal(M)\n",
    "        self.M = nn.Parameter(M, requires_grad = True)\n",
    "\n",
    "    def forward(self, input_seq, response_seq, input_lengths, response_lengths):\n",
    "        context_last_hidden = self.encoder(input_seq, input_lengths) #dimensions: (batch_size x hidden_size)\n",
    "        context_last_hidden = context_last_hidden.to(device)\n",
    "        response_last_hidden = self.encoder(response_seq, response_lengths) #dimensions: (batch_size x hidden_size)\n",
    "        response_last_hidden = response_last_hidden.to(device)\n",
    "        \n",
    "        context = context_last_hidden.mm(self.M) #dimensions: (batch_size x hidden_size)\n",
    "        context = context.view(-1, 1, self.hidden_size) #dimensions: (batch_size x 1 x hidden_size)\n",
    "        context = context.to(device)\n",
    "        \n",
    "        response = response_last_hidden.view(-1, self.hidden_size, 1) #dimensions: (batch_size x hidden_size x 1)\n",
    "        response = response.to(device)\n",
    "        \n",
    "        score = torch.bmm(context, response).view(-1, 1) #dimensions: (batch_size x 1 x 1) and lastly --> (batch_size x 1)\n",
    "        score = score.to(device)\n",
    "\n",
    "        return score\n",
    "    \n",
    "    def forward(self, context_tensor, response_tensor):\n",
    "        \n",
    "        context_last_hidden = self.encoder(context_tensor) #dimensions: (batch_size x hidden_size)\n",
    "        context_last_hidden = context_last_hidden.to(device)\n",
    "        \n",
    "        response_last_hidden = self.encoder(response_tensor) #dimensions: (batch_size x hidden_size)\n",
    "        context = context_last_hidden.mm(self.M) #dimensions: (batch_size x hidden_size)\n",
    "        context = context.view(-1, 1, self.hidden_size) #dimensions: (batch_size x 1 x hidden_size)\n",
    "        context = context.to(device)\n",
    "        \n",
    "        response = response_last_hidden.view(-1, self.hidden_size, 1) #dimensions: (batch_size x hidden_size x 1)\n",
    "        response = response.to(device)\n",
    "        \n",
    "        score = torch.bmm(context, response).view(-1, 1) #dimensions: (batch_size x 1 x 1) and lastly --> (batch_size x 1)\n",
    "        score = score.to(device)\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79ba314f-3995-43e8-b92f-a277a5fecea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_model(emb_dim, hidden_size, vocab_size, p_dropout):\n",
    "\n",
    "    #print(str(datetime.datetime.now()).split('.')[0], \"Calling model...\")\n",
    "\n",
    "    encoder = Encoder(\n",
    "            emb_size = emb_dim,\n",
    "            hidden_size = hidden_size,\n",
    "            vocab_size = vocab_size,\n",
    "            p_dropout = p_dropout)\n",
    "\n",
    "    dual_encoder = DualEncoder(encoder)\n",
    "\n",
    "    #print(str(datetime.datetime.now()).split('.')[0], \"Model created.\\n\")\n",
    "    #print(dual_encoder)\n",
    "    \n",
    "    return encoder, dual_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2843f0c4-2efc-4ed3-a3d7-43d52498359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_count(score, label):\n",
    "    corr = False\n",
    "    if ((score >= 0.5) and (label >= 1)) or ((score < 0.5) and (label  <= 0)):\n",
    "        corr = True\n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_accuracy(correct_count, length):\n",
    "    accuracy = correct_count/length\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09af9860-509b-45b3-b5ac-cc9405eccf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func, is_train = True):\n",
    "\n",
    "    if is_train:\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    context = context.to(device)\n",
    "    response = response.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "    lengths1 = lengths1.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    sum_loss = 0.0\n",
    "    correct_count = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    score = c_encoder(context, response, lengths, lengths1)\n",
    "    total_count = 0\n",
    "    for n in range(len(score)):\n",
    "        label = autograd.Variable(torch.DoubleTensor(torch.from_numpy(np.array(labels[n]).astype(float).reshape(1,1))), requires_grad = False)\n",
    "        label = label.to(device)\n",
    "        #print(score[n].reshape(1,1))\n",
    "        loss = loss_func(score[n].reshape(1,1), label)\n",
    "        sum_loss += loss.item()\n",
    "        if increase_count(score[n].item(), label.item()):\n",
    "            correct_count += 1\n",
    "\n",
    "    if is_train:\n",
    "        # Perform backpropatation\n",
    "        loss.backward()\n",
    "        # Adjust model weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss, correct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b636428c-591b-47d5-926d-d537a67bb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIterAll(training_data, validation_data, c_encoder, learning_rate, l2_penalty, n_iteration, batch_size, epochs):\n",
    "\n",
    "    optimizer = torch.optim.Adam(c_encoder.parameters(), lr = learning_rate, weight_decay = l2_penalty)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "    loss_func = loss_func.to(device)\n",
    "    # Load batches for each iteration\n",
    "    \n",
    "    best_validation_accuracy = 0.0\n",
    "     \n",
    "    for epoch in range(epochs):\n",
    "        training_batches = [batch2TrainData([random.choice(training_data) for _ in range(batch_size)])\n",
    "                          for _ in range(n_iteration)]\n",
    "\n",
    "        validation_batches = [batch2TrainData([random.choice(validation_data) for _ in range(batch_size)])\n",
    "                          for _ in range(n_iteration)]\n",
    "\n",
    "        # Initializations\n",
    "        print('Initializing ...')\n",
    "        start_iteration = 1\n",
    "        print_loss = 0\n",
    "\n",
    "        sum_loss_training = 0.0\n",
    "        training_correct_count = 0\n",
    "        training_total_count = 0\n",
    "        c_encoder.train()\n",
    "\n",
    "        # Training loop\n",
    "        print(\"Training...\")\n",
    "        i = 0\n",
    "        for iteration in range(start_iteration, n_iteration + 1):\n",
    "            if (i % 1000 == 0):\n",
    "                print('Iteration ', i)\n",
    "            i += 1\n",
    "            training_batch = training_batches[iteration - 1]\n",
    "            # Extract fields from batch\n",
    "            context, lengths, response, lengths1, labels = training_batch\n",
    "\n",
    "            # Run a training iteration with batch\n",
    "            loss, correct_count = train(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func)\n",
    "            training_correct_count += correct_count\n",
    "            training_total_count += 64\n",
    "            sum_loss_training += loss\n",
    "            print_loss += loss\n",
    "\n",
    "            # Print progress\n",
    "            if iteration % 1000 == 0:\n",
    "                print_loss_avg = print_loss / 1000\n",
    "                print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "                print('Correct count: ', training_correct_count)\n",
    "                print('Total count: ', training_total_count)\n",
    "                print_loss = 0\n",
    "\n",
    "        training_accuracy = get_accuracy(training_correct_count, training_total_count)\n",
    "        c_encoder.eval()\n",
    "        \n",
    "        # Iterate through validation set\n",
    "        validation_correct_count = 0\n",
    "        validation_total_count = 0\n",
    "        sum_loss_validation = 0.0\n",
    "        i = 0\n",
    "        for iteration in range(start_iteration, n_iteration + 1):\n",
    "            if (i % 1000 == 0):\n",
    "                print('Iteration val ', i)\n",
    "            i += 1\n",
    "            validation_batch = validation_batches[iteration - 1]\n",
    "            # Extract fields from batch\n",
    "            context, lengths, response, lengths1, labels = validation_batch\n",
    "\n",
    "            # Run a training iteration with batch\n",
    "            loss, correct_count = train(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func, False)\n",
    "            sum_loss_validation += loss\n",
    "            validation_correct_count += correct_count\n",
    "            validation_total_count += 64\n",
    "\n",
    "        validation_accuracy = get_accuracy(validation_correct_count, validation_total_count)\n",
    "\n",
    "        print(str(datetime.datetime.now()).split('.')[0], \n",
    "              \"Epoch: %d/%d\" %(epoch,epochs),  \n",
    "              \"TrainLoss: %.3f\" %(sum_loss_training/validation_total_count), \n",
    "              \"TrainAccuracy: %.3f\" %(training_accuracy), \n",
    "              \"ValLoss: %.3f\" %(sum_loss_validation/validation_total_count), \n",
    "              \"ValAccuracy: %.3f\" %(validation_accuracy))\n",
    "\n",
    "        if validation_accuracy > best_validation_accuracy:\n",
    "            best_validation_accuracy = validation_accuracy\n",
    "            torch.save(dual_encoder.state_dict(), 'dataset/models/retrieval_encoder_dict.pt')\n",
    "            torch.save(optimizer.state_dict(), 'dataset/models/retrieval_optimizer_dict.pt')\n",
    "            print(\"New best found and saved.\")\n",
    "                \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Training and validation epochs finished.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6ae585d8-63a3-4897-bdfa-7d27358f6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iteration = 4000\n",
    "batch_size = 64\n",
    "training_data, validation_data = prepareData(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "03beb730-650b-4527-b00c-ad1c1d12636b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-28 19:34:46 Calling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-265-e0136534f141>:23: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  init.uniform(self.lstm.weight_ih_l0, a = -0.01, b = 0.01)\n",
      "<ipython-input-265-e0136534f141>:24: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
      "  init.orthogonal(self.lstm.weight_hh_l0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-28 19:34:47 Model created.\n",
      "\n",
      "DualEncoder(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(23978, 50)\n",
      "    (lstm): LSTM(50, 50)\n",
      "    (dropout_layer): Dropout(p=0.85, inplace=False)\n",
      "  )\n",
      ")\n",
      "M\n",
      "encoder.embedding.weight\n",
      "encoder.lstm.weight_ih_l0\n",
      "encoder.lstm.weight_hh_l0\n",
      "encoder.lstm.bias_ih_l0\n",
      "encoder.lstm.bias_hh_l0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-265-e0136534f141>:56: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(M)\n"
     ]
    }
   ],
   "source": [
    "encoder, dual_encoder = creating_model(hidden_size = 50, \n",
    "                                       p_dropout = 0.85)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "dual_encoder = dual_encoder.to(device)\n",
    "#encoder.cuda()\n",
    "#dual_encoder.cuda\n",
    "\n",
    "for name, param in dual_encoder.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "076f5b50-a29b-4a07-9547-fea4245f4d4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ...\n",
      "Training...\n",
      "Iteration  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-435-6238828ae037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m trainIterAll(training_data = training_data, validation_data = validation_data, c_encoder = dual_encoder, learning_rate = 0.0001, l2_penalty = 0.000001, \n\u001b[0m\u001b[0;32m      2\u001b[0m             n_iteration = n_iteration, batch_size = batch_size, epochs = 100)\n",
      "\u001b[1;32m<ipython-input-433-00980514379a>\u001b[0m in \u001b[0;36mtrainIterAll\u001b[1;34m(training_data, validation_data, c_encoder, learning_rate, l2_penalty, n_iteration, batch_size, epochs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m# Run a training iteration with batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrect_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mtraining_correct_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcorrect_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mtraining_total_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-429-5708311a3c28>\u001b[0m in \u001b[0;36mtrain1\u001b[1;34m(context, response, lengths, lengths1, labels, c_encoder, optimizer, loss_func, is_train)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Forward pass through encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mtotal_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-265-e0136534f141>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_seq, response_seq, input_lengths, response_lengths)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m#print('input_seq: ', input_seq)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m#print('response_seq: ', response_seq)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mcontext_last_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#dimensions: (batch_size x hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mcontext_last_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_last_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m#print(context_last_hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-265-e0136534f141>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_seq, input_lengths, hidden)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlast_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#dimensions: (num_layers * num_directions x batch_size x hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mlast_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_hidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#access last lstm layer, dimensions: (batch_size x hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m#print(last_hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    681\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[0;32m    683\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0;32m    684\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "trainIterAll(training_data = training_data, validation_data = validation_data, c_encoder = dual_encoder, learning_rate = 0.0001, l2_penalty = 0.000001, \n",
    "            n_iteration = n_iteration, batch_size = batch_size, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c4b0d-599e-4942-8c60-173c1b529425",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses, vocab, word_to_id, id_to_vec, emb_dim = prepare_responses()\n",
    "encoder, dual_encoder = creating_model(emb_dim = emb_dim, hidden_size = 50, vocab_size = len(vocab), p_dropout = 0.85)\n",
    "encoder = encoder.to(device)\n",
    "dual_encoder = dual_encoder.to(device)\n",
    "dual_encoder.load_state_dict(torch.load('dataset/models/retrieval_encoder_dict.pt'))\n",
    "dual_encoder.eval()\n",
    "\n",
    "context_ids = load_id(context, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "65acec3f-d02d-40de-9108-201efd4101b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getResponse(context):\n",
    "    \n",
    "    i = 0\n",
    "    best_pos = 0\n",
    "    best_score = 0\n",
    "    for response in responses:\n",
    "        if not isinstance(response[0], str):\n",
    "            continue\n",
    "        response_ids = load_id(response[0], word_to_id)\n",
    "        contextt = autograd.Variable(torch.LongTensor(context_ids).view(-1,1))\n",
    "        responset = autograd.Variable(torch.LongTensor(response_ids).view(-1, 1))\n",
    "        contextt, responset = contextt.to(device), responset.to(device)\n",
    "        score = dual_encoder(contextt, responset)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_pos = i\n",
    "        i += 1\n",
    "    return responses[best_pos][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2bcebd68-6d59-4073-8d71-fbe2f8ed55e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like country music , but i like country music , but i like country music\n"
     ]
    }
   ],
   "source": [
    "response = getResponse('how do you do today')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3516572-96bb-4f66-a6f3-62d7f8147290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
